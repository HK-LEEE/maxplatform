#!/usr/bin/env python3
"""
MAX Platform ë°ë“œ ì½”ë“œ ë° ë¯¸ì‚¬ìš© ì˜ì¡´ì„± ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
python scripts/analyze_dead_code.py --all
python scripts/analyze_dead_code.py --deps-only
python scripts/analyze_dead_code.py --imports-only
"""

import os
import json
import re
import ast
import argparse
from pathlib import Path
from collections import defaultdict

class DeadCodeAnalyzer:
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.frontend_src = self.project_root / "frontend/src"
        self.backend_src = self.project_root / "backend"
        
    def analyze_frontend_dependencies(self):
        """Frontend íŒ¨í‚¤ì§€ ì˜ì¡´ì„± ë¶„ì„"""
        print("ğŸ” Frontend ì˜ì¡´ì„± ë¶„ì„...")
        
        package_json = self.project_root / "frontend/package.json"
        if not package_json.exists():
            print("âŒ package.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
            
        with open(package_json) as f:
            package_data = json.load(f)
            
        dependencies = package_data.get("dependencies", {})
        
        # ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” íŒ¨í‚¤ì§€ ì°¾ê¸°
        used_packages = set()
        unused_packages = []
        
        # ëª¨ë“  JS/TS íŒŒì¼ì—ì„œ import êµ¬ë¬¸ ì°¾ê¸°
        for file_path in self.frontend_src.rglob("*.{js,jsx,ts,tsx}"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # import êµ¬ë¬¸ íŒ¨í„´ ë§¤ì¹­
                import_patterns = [
                    r"import.*from\s+['\"]([^'\"]+)['\"]",
                    r"import\s+['\"]([^'\"]+)['\"]",
                    r"require\s*\(\s*['\"]([^'\"]+)['\"]\s*\)"
                ]
                
                for pattern in import_patterns:
                    matches = re.findall(pattern, content)
                    for match in matches:
                        # ìƒëŒ€ ê²½ë¡œê°€ ì•„ë‹Œ íŒ¨í‚¤ì§€ëª…ë§Œ ì¶”ì¶œ
                        if not match.startswith('.'):
                            package_name = match.split('/')[0]
                            used_packages.add(package_name)
                            
            except Exception as e:
                print(f"âš ï¸  {file_path} ë¶„ì„ ì‹¤íŒ¨: {e}")
                
        # ë¯¸ì‚¬ìš© íŒ¨í‚¤ì§€ ì°¾ê¸°
        for package in dependencies:
            if package not in used_packages:
                # íŠ¹ë³„í•œ ì¼€ì´ìŠ¤ë“¤ ì²´í¬
                special_cases = {
                    'typescript': 'TypeScript ì»´íŒŒì¼ëŸ¬',
                    'tailwindcss': 'CSS í”„ë ˆì„ì›Œí¬ (ì„¤ì • íŒŒì¼ì—ì„œ ì‚¬ìš©)',
                    'autoprefixer': 'PostCSS í”ŒëŸ¬ê·¸ì¸',
                    'postcss': 'CSS í›„ì²˜ë¦¬ê¸°'
                }
                
                if package in special_cases:
                    print(f"ğŸ”§ {package}: {special_cases[package]} (ì„¤ì •ì—ì„œ ì‚¬ìš©)")
                else:
                    unused_packages.append(package)
                    
        print(f"\nğŸ“Š Frontend ì˜ì¡´ì„± ë¶„ì„ ê²°ê³¼:")
        print(f"   ì „ì²´ ì˜ì¡´ì„±: {len(dependencies)}ê°œ")
        print(f"   ì‚¬ìš© ì¤‘: {len(used_packages)}ê°œ")
        print(f"   ë¯¸ì‚¬ìš© ì˜ì‹¬: {len(unused_packages)}ê°œ")
        
        if unused_packages:
            print(f"\nğŸ—‘ï¸  ë¯¸ì‚¬ìš© ì˜ì‹¬ íŒ¨í‚¤ì§€:")
            for package in unused_packages:
                version = dependencies[package]
                print(f"   {package}: {version}")
                
        return unused_packages
        
    def analyze_unused_imports(self):
        """ë¯¸ì‚¬ìš© import ë¶„ì„"""
        print("\nğŸ” ë¯¸ì‚¬ìš© import ë¶„ì„...")
        
        unused_imports = []
        
        # Python íŒŒì¼ë“¤ ë¶„ì„
        for file_path in self.backend_src.rglob("*.py"):
            if "test" in str(file_path) or "__pycache__" in str(file_path):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # ASTë¡œ íŒŒì‹±
                tree = ast.parse(content)
                
                # import êµ¬ë¬¸ë“¤ ì°¾ê¸°
                imports = []
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports.append(alias.name)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            for alias in node.names:
                                imports.append(f"{node.module}.{alias.name}")
                                
                # ì‹¤ì œ ì‚¬ìš© ì—¬ë¶€ ì²´í¬ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
                for imported in imports:
                    simple_name = imported.split('.')[-1]
                    if simple_name not in content.replace(f"import {imported}", ""):
                        unused_imports.append((file_path, imported))
                        
            except Exception as e:
                continue  # íŒŒì‹± ì—ëŸ¬ëŠ” ë¬´ì‹œ
                
        print(f"ğŸ“Š ë¯¸ì‚¬ìš© import ë¶„ì„ ê²°ê³¼: {len(unused_imports)}ê°œ ë°œê²¬")
        
        if unused_imports:
            print("\nğŸ—‘ï¸  ë¯¸ì‚¬ìš© import ëª©ë¡ (ì¼ë¶€):")
            for file_path, imported in unused_imports[:10]:  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
                rel_path = file_path.relative_to(self.project_root)
                print(f"   {rel_path}: {imported}")
                
            if len(unused_imports) > 10:
                print(f"   ... ë° {len(unused_imports) - 10}ê°œ ë”")
                
        return unused_imports
        
    def analyze_unused_components(self):
        """ë¯¸ì‚¬ìš© React ì»´í¬ë„ŒíŠ¸ ë¶„ì„"""
        print("\nğŸ” ë¯¸ì‚¬ìš© React ì»´í¬ë„ŒíŠ¸ ë¶„ì„...")
        
        # ëª¨ë“  ì»´í¬ë„ŒíŠ¸ íŒŒì¼ ì°¾ê¸°
        component_files = []
        for file_path in self.frontend_src.rglob("*.{jsx,tsx}"):
            if file_path.name != "App.tsx" and file_path.name != "main.tsx":
                component_files.append(file_path)
                
        # ê° ì»´í¬ë„ŒíŠ¸ì˜ ì‚¬ìš© ì—¬ë¶€ ì²´í¬
        unused_components = []
        
        for comp_file in component_files:
            comp_name = comp_file.stem
            is_used = False
            
            # ë‹¤ë¥¸ íŒŒì¼ë“¤ì—ì„œ ì´ ì»´í¬ë„ŒíŠ¸ë¥¼ importí•˜ëŠ”ì§€ ì²´í¬
            for check_file in self.frontend_src.rglob("*.{js,jsx,ts,tsx}"):
                if check_file == comp_file:
                    continue
                    
                try:
                    with open(check_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    # import íŒ¨í„´ë“¤ ì²´í¬
                    import_patterns = [
                        rf"import.*{comp_name}.*from",
                        rf"import\s+\{{[^}}]*{comp_name}[^}}]*\}}",
                        rf"<{comp_name}[>\s]"
                    ]
                    
                    for pattern in import_patterns:
                        if re.search(pattern, content):
                            is_used = True
                            break
                            
                    if is_used:
                        break
                        
                except Exception:
                    continue
                    
            if not is_used:
                unused_components.append(comp_file)
                
        print(f"ğŸ“Š ì»´í¬ë„ŒíŠ¸ ë¶„ì„ ê²°ê³¼:")
        print(f"   ì „ì²´ ì»´í¬ë„ŒíŠ¸: {len(component_files)}ê°œ")
        print(f"   ë¯¸ì‚¬ìš© ì˜ì‹¬: {len(unused_components)}ê°œ")
        
        if unused_components:
            print(f"\nğŸ—‘ï¸  ë¯¸ì‚¬ìš© ì˜ì‹¬ ì»´í¬ë„ŒíŠ¸:")
            for comp_file in unused_components:
                rel_path = comp_file.relative_to(self.frontend_src)
                print(f"   {rel_path}")
                
        return unused_components
        
    def analyze_duplicate_utilities(self):
        """ì¤‘ë³µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¶„ì„"""
        print("\nğŸ” ì¤‘ë³µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¶„ì„...")
        
        # ìœ í‹¸ë¦¬í‹° ë””ë ‰í† ë¦¬ë“¤ ìŠ¤ìº”
        util_dirs = [
            self.frontend_src / "utils",
            self.backend_src / "app/utils"
        ]
        
        function_signatures = defaultdict(list)
        
        for util_dir in util_dirs:
            if not util_dir.exists():
                continue
                
            for file_path in util_dir.rglob("*.{py,js,ts}"):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    # í•¨ìˆ˜ ì •ì˜ íŒ¨í„´ ì°¾ê¸°
                    patterns = [
                        r"def\s+(\w+)\s*\(",  # Python
                        r"function\s+(\w+)\s*\(",  # JavaScript
                        r"const\s+(\w+)\s*=.*=>",  # Arrow function
                        r"export\s+const\s+(\w+)\s*="  # Export const
                    ]
                    
                    for pattern in patterns:
                        matches = re.findall(pattern, content)
                        for match in matches:
                            function_signatures[match].append(file_path)
                            
                except Exception:
                    continue
                    
        # ì¤‘ë³µ í•¨ìˆ˜ë“¤ ì°¾ê¸°
        duplicates = {name: files for name, files in function_signatures.items() 
                     if len(files) > 1}
                     
        print(f"ğŸ“Š ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¤‘ë³µ ë¶„ì„:")
        print(f"   ì¤‘ë³µ í•¨ìˆ˜ëª…: {len(duplicates)}ê°œ")
        
        if duplicates:
            print(f"\nğŸ”„ ì¤‘ë³µëœ í•¨ìˆ˜ë“¤:")
            for func_name, files in list(duplicates.items())[:5]:  # ìƒìœ„ 5ê°œë§Œ
                print(f"   {func_name}:")
                for file_path in files:
                    rel_path = file_path.relative_to(self.project_root)
                    print(f"     - {rel_path}")
                    
        return duplicates
        
    def generate_optimization_recommendations(self, analysis_results):
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        print("\n" + "="*60)
        print("ğŸ’¡ í”„ë¡œì íŠ¸ ìµœì í™” ê¶Œì¥ì‚¬í•­")
        print("="*60)
        
        unused_deps = analysis_results.get('unused_dependencies', [])
        unused_components = analysis_results.get('unused_components', [])
        duplicates = analysis_results.get('duplicates', {})
        
        recommendations = []
        
        if unused_deps:
            recommendations.append({
                'priority': 'HIGH',
                'category': 'ì˜ì¡´ì„± ì •ë¦¬',
                'action': f'{len(unused_deps)}ê°œ ë¯¸ì‚¬ìš© íŒ¨í‚¤ì§€ ì œê±°',
                'command': f'npm uninstall {" ".join(unused_deps)}',
                'impact': 'ë²ˆë“¤ í¬ê¸° ê°ì†Œ, ë³´ì•ˆ ìœ„í—˜ ê°ì†Œ'
            })
            
        if unused_components:
            recommendations.append({
                'priority': 'MEDIUM',
                'category': 'ì»´í¬ë„ŒíŠ¸ ì •ë¦¬',
                'action': f'{len(unused_components)}ê°œ ë¯¸ì‚¬ìš© ì»´í¬ë„ŒíŠ¸ ì œê±°',
                'command': 'ìˆ˜ë™ ê²€í†  í›„ ì‚­ì œ',
                'impact': 'ì½”ë“œë² ì´ìŠ¤ ë‹¨ìˆœí™”'
            })
            
        if duplicates:
            recommendations.append({
                'priority': 'MEDIUM', 
                'category': 'ì¤‘ë³µ ì œê±°',
                'action': f'{len(duplicates)}ê°œ ì¤‘ë³µ í•¨ìˆ˜ í†µí•©',
                'command': 'ìˆ˜ë™ ë¦¬íŒ©í† ë§',
                'impact': 'ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ'
            })
            
        # ê¶Œì¥ì‚¬í•­ ì¶œë ¥
        for i, rec in enumerate(recommendations, 1):
            print(f"\n{i}. [{rec['priority']}] {rec['category']}")
            print(f"   ğŸ“‹ ì‘ì—…: {rec['action']}")
            print(f"   ğŸ’» ëª…ë ¹ì–´: {rec['command']}")
            print(f"   ğŸ¯ íš¨ê³¼: {rec['impact']}")
            
        return recommendations

def main():
    parser = argparse.ArgumentParser(description='MAX Platform ë°ë“œ ì½”ë“œ ë¶„ì„ ë„êµ¬')
    parser.add_argument('--all', action='store_true', default=True,
                       help='ì „ì²´ ë¶„ì„ (ê¸°ë³¸ê°’)')
    parser.add_argument('--deps-only', action='store_true',
                       help='ì˜ì¡´ì„±ë§Œ ë¶„ì„')
    parser.add_argument('--imports-only', action='store_true',
                       help='importë§Œ ë¶„ì„')
    parser.add_argument('--components-only', action='store_true',
                       help='ì»´í¬ë„ŒíŠ¸ë§Œ ë¶„ì„')
    
    args = parser.parse_args()
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ìë™ ê°ì§€
    current_dir = Path.cwd()
    if current_dir.name == 'maxplatform':
        project_root = current_dir
    elif (current_dir.parent / 'maxplatform').exists():
        project_root = current_dir.parent / 'maxplatform'
    else:
        project_root = Path('/home/lee/proejct/maxplatform')
        
    if not project_root.exists():
        print(f"âŒ í”„ë¡œì íŠ¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_root}")
        return
        
    analyzer = DeadCodeAnalyzer(project_root)
    
    print(f"ğŸš€ MAX Platform ë°ë“œ ì½”ë“œ ë¶„ì„ ì‹œì‘")
    print(f"ğŸ“ í”„ë¡œì íŠ¸ ê²½ë¡œ: {project_root}")
    
    analysis_results = {}
    
    # ë¶„ì„ ì‹¤í–‰
    if args.deps_only or args.all:
        analysis_results['unused_dependencies'] = analyzer.analyze_frontend_dependencies()
        
    if args.imports_only or args.all:
        analysis_results['unused_imports'] = analyzer.analyze_unused_imports()
        
    if args.components_only or args.all:
        analysis_results['unused_components'] = analyzer.analyze_unused_components()
        
    if args.all:
        analysis_results['duplicates'] = analyzer.analyze_duplicate_utilities()
        
    # ê¶Œì¥ì‚¬í•­ ìƒì„±
    if args.all:
        analyzer.generate_optimization_recommendations(analysis_results)

if __name__ == "__main__":
    main()