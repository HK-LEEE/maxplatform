#!/usr/bin/env python3
"""
MAX Platform í”„ë¡œì íŠ¸ ìë™ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
ë¶ˆí•„ìš”í•œ íŒŒì¼, ë”í‹° íŒŒì¼, ë¯¸ì‚¬ìš© ì½”ë“œ ì •ë¦¬

ì‚¬ìš©ë²•:
python scripts/cleanup_project.py --dry-run    # ë¯¸ë¦¬ë³´ê¸°
python scripts/cleanup_project.py --execute    # ì‹¤ì œ ì‹¤í–‰
python scripts/cleanup_project.py --logs-only  # ë¡œê·¸ íŒŒì¼ë§Œ ì •ë¦¬
"""

import os
import sys
import glob
import shutil
import argparse
import json
from pathlib import Path
from datetime import datetime, timedelta

class ProjectCleaner:
    def __init__(self, project_root, dry_run=True):
        self.project_root = Path(project_root)
        self.dry_run = dry_run
        self.deleted_files = []
        self.saved_space = 0
        
    def log_action(self, action, file_path, reason=""):
        if self.dry_run:
            print(f"[DRY-RUN] {action}: {file_path} {reason}")
        else:
            print(f"[EXECUTED] {action}: {file_path} {reason}")
            
    def get_file_size(self, file_path):
        try:
            return os.path.getsize(file_path)
        except:
            return 0
            
    def delete_file(self, file_path, reason=""):
        file_size = self.get_file_size(file_path)
        self.log_action("DELETE", file_path, f"({reason})")
        
        if not self.dry_run:
            try:
                os.remove(file_path)
                self.deleted_files.append(str(file_path))
                self.saved_space += file_size
            except Exception as e:
                print(f"ERROR deleting {file_path}: {e}")
                
    def cleanup_zone_identifier_files(self):
        """Windows Zone.Identifier íŒŒì¼ ì •ë¦¬"""
        print("\nğŸ” Zone.Identifier íŒŒì¼ ì •ë¦¬...")
        
        zone_files = list(self.project_root.rglob("*:Zone.Identifier"))
        for file_path in zone_files:
            self.delete_file(file_path, "Windows Zone.Identifier íŒŒì¼")
            
        return len(zone_files)
        
    def cleanup_backup_files(self):
        """ë°±ì—… ë° ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        print("\nğŸ” ë°±ì—… ë° ì„ì‹œ íŒŒì¼ ì •ë¦¬...")
        
        patterns = [
            "*_backup*",
            "*_new*", 
            "*_old*",
            "*_temp*",
            "*.tmp",
            "*.bak"
        ]
        
        deleted_count = 0
        for pattern in patterns:
            for file_path in self.project_root.rglob(pattern):
                if file_path.is_file():
                    # .venv, node_modules ë“± ì œì™¸
                    if any(exclude in str(file_path) for exclude in ['.venv', 'node_modules', '__pycache__']):
                        continue
                    self.delete_file(file_path, f"ë°±ì—…/ì„ì‹œ íŒŒì¼ ({pattern})")
                    deleted_count += 1
                    
        # íŠ¹ì • íŒŒì¼ë“¤
        specific_files = [
            "backend/test/jupyter_platform.db",
            "frontend/src/App_backup.tsx",
            "frontend/src/App_new.tsx"
        ]
        
        for file_rel_path in specific_files:
            file_path = self.project_root / file_rel_path
            if file_path.exists():
                self.delete_file(file_path, "ë¯¸ì‚¬ìš© ë°±ì—… íŒŒì¼")
                deleted_count += 1
                
        return deleted_count
        
    def cleanup_duplicate_components(self):
        """ì¤‘ë³µ ì»´í¬ë„ŒíŠ¸ ì •ë¦¬"""
        print("\nğŸ” ì¤‘ë³µ ì»´í¬ë„ŒíŠ¸ ì •ë¦¬...")
        
        # ProtectedRoute ì¤‘ë³µ ì œê±° (JSX ë²„ì „ ì‚­ì œ, TSX ìœ ì§€)
        jsx_file = self.project_root / "frontend/src/components/ProtectedRoute.jsx"
        if jsx_file.exists():
            self.delete_file(jsx_file, "TSX ë²„ì „ìœ¼ë¡œ í†µí•©")
            return 1
            
        return 0
        
    def cleanup_old_logs(self, days_to_keep=7):
        """ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì •ë¦¬"""
        print(f"\nğŸ” {days_to_keep}ì¼ ì´ì „ ë¡œê·¸ íŒŒì¼ ì •ë¦¬...")
        
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        deleted_count = 0
        
        log_patterns = [
            "backend/logs/*.log.*",
            "backend/logs/*_2025_*",
            "backend/logs/test_*.log"
        ]
        
        for pattern in log_patterns:
            for file_path in self.project_root.glob(pattern):
                if file_path.is_file():
                    # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
                    file_mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                    if file_mtime < cutoff_date:
                        self.delete_file(file_path, f"{days_to_keep}ì¼ ì´ì „ ë¡œê·¸")
                        deleted_count += 1
                        
        return deleted_count
        
    def cleanup_redundant_docs(self):
        """ì¤‘ë³µ ë¬¸ì„œ ì •ë¦¬ (ìˆ˜ë™ í™•ì¸ í•„ìš”)"""
        print("\nğŸ” ì¤‘ë³µ ë¬¸ì„œ ë¶„ì„ (ìˆ˜ë™ í™•ì¸ ê¶Œì¥)...")
        
        oauth_docs = [
            "MAX_Platform_OAuth_Integration_Guide_imp(real).md",
            "docs/MAX_Platform_OAuth2_Integration_Guide.md", 
            "backend/docs/MAX_Platform_OAuth_Integration_Guide_imp(real).md",
            "backend/docs/MAX_Platform_OAuth_2.0_Complete_Developer_Guide.md"
        ]
        
        print("ğŸ“‹ ë°œê²¬ëœ OAuth ë¬¸ì„œë“¤:")
        for doc in oauth_docs:
            full_path = self.project_root / doc
            if full_path.exists():
                size = self.get_file_size(full_path)
                print(f"   {doc} ({size:,} bytes)")
                
        print("âš ï¸  ìˆ˜ë™ ê²€í†  í›„ ë¶ˆí•„ìš”í•œ ë¬¸ì„œ ì œê±° ê¶Œì¥")
        return 0
        
    def analyze_unused_dependencies(self):
        """ë¯¸ì‚¬ìš© ì˜ì¡´ì„± ë¶„ì„"""
        print("\nğŸ” ë¯¸ì‚¬ìš© ì˜ì¡´ì„± ë¶„ì„...")
        
        package_json = self.project_root / "frontend/package.json"
        if package_json.exists():
            with open(package_json) as f:
                package_data = json.load(f)
                
            deps_to_check = ["react-hook-form"]
            
            print("ğŸ“‹ ì˜ì‹¬ë˜ëŠ” ë¯¸ì‚¬ìš© ì˜ì¡´ì„±:")
            for dep in deps_to_check:
                if dep in package_data.get("dependencies", {}):
                    print(f"   {dep}: {package_data['dependencies'][dep]}")
                    print(f"      í”„ë¡œì íŠ¸ ë‚´ ì‚¬ìš©ì²˜ ê²€ìƒ‰ ê¶Œì¥")
                    
        return 0
        
    def cleanup_test_files(self, aggressive=False):
        """í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬ (ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ)"""
        print("\nğŸ” í…ŒìŠ¤íŠ¸ íŒŒì¼ ë¶„ì„...")
        
        test_dir = self.project_root / "backend/test"
        if test_dir.exists():
            test_files = list(test_dir.glob("*.py"))
            print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ì— {len(test_files)}ê°œ íŒŒì¼ ë°œê²¬")
            
            if aggressive:
                # ëª…ë°±íˆ ì„ì‹œ/ë””ë²„ê·¸ìš©ì¸ íŒŒì¼ë“¤ë§Œ ì‚­ì œ
                temp_patterns = [
                    "debug_*",
                    "test_*_debug*", 
                    "*_temp*"
                ]
                
                deleted_count = 0
                for pattern in temp_patterns:
                    for file_path in test_dir.glob(pattern):
                        self.delete_file(file_path, "ì„ì‹œ ë””ë²„ê·¸ íŒŒì¼")
                        deleted_count += 1
                        
                return deleted_count
            else:
                print("âš ï¸  ìˆ˜ë™ ê²€í†  ê¶Œì¥ (--aggressive í”Œë˜ê·¸ë¡œ ì„ì‹œ íŒŒì¼ë§Œ ì‚­ì œ ê°€ëŠ¥)")
                
        return 0
        
    def generate_cleanup_report(self):
        """ì •ë¦¬ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        print("\n" + "="*60)
        print("ğŸ“Š í”„ë¡œì íŠ¸ ì •ë¦¬ ê²°ê³¼ ë³´ê³ ì„œ")
        print("="*60)
        
        if self.dry_run:
            print("ğŸ” DRY RUN ëª¨ë“œ - ì‹¤ì œ íŒŒì¼ì€ ì‚­ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        else:
            print(f"âœ… {len(self.deleted_files)}ê°œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
            print(f"ğŸ’¾ ì ˆì•½ëœ ê³µê°„: {self.saved_space:,} bytes ({self.saved_space/1024/1024:.2f} MB)")
            
        print("\nğŸ“‹ ìˆ˜ë™ ê²€í†  ê¶Œì¥ í•­ëª©:")
        print("   1. OAuth ë¬¸ì„œ ì¤‘ë³µ í™•ì¸")
        print("   2. react-hook-form ì˜ì¡´ì„± ì œê±° ì—¬ë¶€")
        print("   3. backend/test ë””ë ‰í† ë¦¬ ì •ë¦¬")
        print("   4. ìƒˆ í´ë”/ ë‚´ìš© í™•ì¸")
        
    def run_cleanup(self, options):
        """ì „ì²´ ì •ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print(f"ğŸš€ MAX Platform í”„ë¡œì íŠ¸ ì •ë¦¬ ì‹œì‘")
        print(f"ğŸ“ í”„ë¡œì íŠ¸ ê²½ë¡œ: {self.project_root}")
        print(f"ğŸ”§ ëª¨ë“œ: {'DRY RUN' if self.dry_run else 'EXECUTE'}")
        
        total_cleaned = 0
        
        if options.get('zone_files', True):
            total_cleaned += self.cleanup_zone_identifier_files()
            
        if options.get('backup_files', True):
            total_cleaned += self.cleanup_backup_files()
            
        if options.get('duplicates', True):
            total_cleaned += self.cleanup_duplicate_components()
            
        if options.get('logs', True):
            total_cleaned += self.cleanup_old_logs(options.get('log_days', 7))
            
        if options.get('docs', True):
            total_cleaned += self.cleanup_redundant_docs()
            
        if options.get('deps', True):
            total_cleaned += self.analyze_unused_dependencies()
            
        if options.get('tests', True):
            total_cleaned += self.cleanup_test_files(options.get('aggressive', False))
            
        self.generate_cleanup_report()
        return total_cleaned

def main():
    parser = argparse.ArgumentParser(description='MAX Platform í”„ë¡œì íŠ¸ ì •ë¦¬ ë„êµ¬')
    parser.add_argument('--dry-run', action='store_true', default=True,
                       help='ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ (ê¸°ë³¸ê°’)')
    parser.add_argument('--execute', action='store_true',
                       help='ì‹¤ì œ ì‚­ì œ ì‹¤í–‰')
    parser.add_argument('--logs-only', action='store_true',
                       help='ë¡œê·¸ íŒŒì¼ë§Œ ì •ë¦¬')
    parser.add_argument('--aggressive', action='store_true',
                       help='ì„ì‹œ í…ŒìŠ¤íŠ¸ íŒŒì¼ë„ ì‚­ì œ')
    parser.add_argument('--log-days', type=int, default=7,
                       help='ë³´ê´€í•  ë¡œê·¸ íŒŒì¼ ì¼ìˆ˜ (ê¸°ë³¸: 7ì¼)')
    
    args = parser.parse_args()
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ìë™ ê°ì§€
    current_dir = Path.cwd()
    if current_dir.name == 'maxplatform':
        project_root = current_dir
    elif (current_dir.parent / 'maxplatform').exists():
        project_root = current_dir.parent / 'maxplatform'
    else:
        project_root = Path('/home/lee/proejct/maxplatform')
        
    if not project_root.exists():
        print(f"âŒ í”„ë¡œì íŠ¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_root}")
        sys.exit(1)
        
    # ì‹¤í–‰ ëª¨ë“œ ì„¤ì •
    dry_run = not args.execute
    
    cleaner = ProjectCleaner(project_root, dry_run=dry_run)
    
    # ì •ë¦¬ ì˜µì…˜ ì„¤ì •
    if args.logs_only:
        options = {
            'zone_files': False,
            'backup_files': False,
            'duplicates': False,
            'logs': True,
            'docs': False,
            'deps': False,
            'tests': False,
            'log_days': args.log_days
        }
    else:
        options = {
            'zone_files': True,
            'backup_files': True, 
            'duplicates': True,
            'logs': True,
            'docs': True,
            'deps': True,
            'tests': True,
            'aggressive': args.aggressive,
            'log_days': args.log_days
        }
    
    # ì •ë¦¬ ì‹¤í–‰
    try:
        cleaned_count = cleaner.run_cleanup(options)
        print(f"\nâœ¨ ì •ë¦¬ ì™„ë£Œ! ì´ {cleaned_count}ê°œ í•­ëª© ì²˜ë¦¬ë¨")
        
        if dry_run:
            print("\nğŸ’¡ ì‹¤ì œ ì‚­ì œí•˜ë ¤ë©´ --execute í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
            
    except KeyboardInterrupt:
        print("\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()